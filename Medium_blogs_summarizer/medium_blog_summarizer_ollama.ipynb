{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712e080c-c454-4b85-bf56-91922f254a0a",
   "metadata": {},
   "source": [
    "# Medium Blog Summarizer - With Ollama using OpenAI API Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac2a73f-837b-4637-b197-d2e9a4c7af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41263e6f-5691-4ec9-93a8-e859a83fa396",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_guru = \"You are a scientific assistant. You have to help summarize a blog post.\\\n",
    "Please tell about the most important findings and anything the author emphasizes.\\\n",
    "Give the output in markdown.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95c27e9-c795-46d5-b4ce-4cec83b08cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "guru_blog = \"https://gurudeep1998.medium.com/w-net-a-deep-model-for-fully-unsupervised-image-segmentation-reproduction-2651540eaed6\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b3fc54-9a38-4345-8e1b-868e2b3c8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama runs a server where requests can be sent for computation\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3244a462-58e7-4ba6-8dcc-41369ff795c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for_blog(website):\n",
    "    user_prompt = f\"You are looking at a blog titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this blog is as follows; \\\n",
    "please provide a summary of this blog in markdown. \\\n",
    "If it includes references any research papers and github links, please provide their links also.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def summarize_medium_blog_ollama(url, system_prompt, model=\"llama3.2\"):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "           {\"role\": \"user\", \"content\": user_prompt_for_blog(website)}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cbea18e-b21e-4e22-89d2-a4701124409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a lengthy response about reconstructing the W-Net model for fully unsupervised image segmentation, written in a format that mimics academic papers and research articles. Here's a breakdown of the main points:\n",
       "\n",
       "**Introduction**\n",
       "\n",
       "The authors began by introducing the W-Net model, which is used for fully unsupervised image segmentation. They aimed to reconstruct this model using three existing GitHub repositories and share their results.\n",
       "\n",
       "**Reconstruction Process**\n",
       "\n",
       "To reconstruct the W-Net model, the authors:\n",
       "\n",
       "1. Combined and adjusted three existing GitHub repositories:\n",
       "\t* [2] as a base repository\n",
       "\t* [3] to increase computational efficiency by changing the soft N-cut loss\n",
       "\t* [4] to evaluate metrics for the results\n",
       "2.Defined the Soft-N-cut loss from [3]\n",
       "3. Updated the optimizer parameters\n",
       "4. Implemented learning schedules\n",
       "\n",
       "**Results**\n",
       "\n",
       "The authors reported mixed results, with both visually pleasing segmentations and lower performance compared to the original paper.\n",
       "\n",
       "**Comparison to Original Paper**\n",
       "\n",
       "* The magnitude of losses was higher in their implementation.\n",
       "* Performance metrics were lower, although they were still close to the original results.\n",
       "\n",
       "**Discussion**\n",
       "\n",
       "The authors discussed potential reasons for the differences between their implementation and the original paper, such as:\n",
       "\n",
       "* Missing hyperparameters (e.g., number of classes \"K\", kind of optimizer) in the original paper\n",
       "* Differences in parameter choices due to unavailability in the original paper\n",
       "* Non-existence of learning schedules\n",
       "\n",
       "**Conclusion**\n",
       "\n",
       "The authors concluded that their project aimed to recreate the W-Net model for fully unsupervised image segmentation, with mixed results. They noted that the process was complex and relied on many assumptions.\n",
       "\n",
       "**Bibliography**\n",
       "\n",
       "A comprehensive list of sources cited in the paper, including academic articles, books, and online resources."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(display(Markdown(summarize_medium_blog_ollama(guru_blog, system_prompt_guru, \"llama3.2\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e45abac-11a0-41a1-8f3f-d7a57ca9f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's check with another model\n",
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fffcb036-7572-4080-aaa2-41a585b0041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I'm trying to follow the instructions given. The user has a detailed explanation of a paper implementation involving three existing GitHub repositories and an analysis of that paper. Now, I need to figure out what the next step should be based on this information.\n",
       "\n",
       "First, I'll start by reviewing the details provided to me. There's a response from the assistant that explains each section (Sections I-V) as per the user's request. It includes how they implemented the model and their analysis of the paper.\n",
       "\n",
       "I think my response should clearly outline these steps. Maybe the assistant wants an example or a detailed explanation for someone else who is trying to replicate this project. So, perhaps suggesting a follow-up could guide them on what to do next after their initial attempt.\n",
       "\n",
       "Alternatively, maybe they want something more structured or a summary of what I can contribute. In that case, listing out each section in order might help them understand the continuation needed once they have their repository ready.\n",
       "\n",
       "I need to make sure my reply is clear and guides them through the next step correctly. Perhaps breaking down the sections briefly could be useful for someone who isn't entirely sure where to start after initial implementation.\n",
       "</think>\n",
       "\n",
       "Here’s a follow-up that can guide your next steps:\n",
       "\n",
       "---\n",
       "\n",
       "To proceed with your implementation, complete three things:\n",
       "1. Write your own implementation with all provided files (including `github.comwnet-unsupervised-image-segmentation.py`, `keromod/wnet-unsupervised-image-segmentation.ipynb`).\n",
       "2. Fix any errors in your code you discovered.\n",
       "3. Generate a pull request for [GitHub](https://github.com), indicating the changes you've made and attaching your complete Jupyter notebook with the training log.\n",
       "\n",
       "This ensures your implementation is thorough and community-friendly, making your contribution more impactful.\n",
       "\n",
       "--- \n",
       "\n",
       "Let me know if this aligns better with your goals!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(display(Markdown(summarize_medium_blog_ollama(guru_blog, system_prompt_guru, \"deepseek-r1:1.5b\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2b34f-0015-4eae-9ad3-d8ebd788889b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
