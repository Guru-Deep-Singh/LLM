{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2b4feb-ba7b-4574-bea4-f28530b59856",
   "metadata": {},
   "source": [
    "# Multi Modal CodeBuddy: Audio Input support\n",
    "**Support**\n",
    "- LLM model:\n",
    "    - OpenAI: gpt-4o-mini\n",
    "    - ollama: llama3.2\n",
    "- Trancribing model:\n",
    "    - OpenAI: whisper-1\n",
    "    - whisper: base, small, medium, large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86e369-e2dc-458b-a724-264eedb8e070",
   "metadata": {},
   "source": [
    "![MM_Gradio Based Chatbot](../images/MM_chatbot_code_buddy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e8170-1f94-4964-954f-a8b076fa8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7e965-169f-4603-9ee3-1042b99f9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the CodeBuddy class\n",
    "localPath = \"../Code_Buddy/\"\n",
    "absolutePath = os.path.abspath(localPath)\n",
    "\n",
    "if absolutePath not in sys.path:\n",
    "    sys.path.append(absolutePath)\n",
    "\n",
    "from CodeBuddy import CodeBuddy       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2284c1d-c63b-42b9-9016-f7338be16a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Transcriber class\n",
    "localPath = \"../Transcriber/\"\n",
    "absolutePath = os.path.abspath(localPath)\n",
    "\n",
    "if absolutePath not in sys.path:\n",
    "    sys.path.append(absolutePath)\n",
    "\n",
    "from Transcriber import Transcriber     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821d166-0c08-40d1-9034-a3b933f2497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"You are a helpful and informed coding agent.\\\n",
    "            You are given a piece of code. You have to check if the code is correct or is incorrect.\\\n",
    "            You need to explain the code in beginner friendly way.\\\n",
    "            You are also allowed to give suggestions on improvement of code for runtime optimization.\\\n",
    "            Give your answer in Markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee213d-34c2-4d42-b77b-7154edf74d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def initialize_buddy(model):\n",
    "    if model == \"gpt-4o-mini\":\n",
    "        gr.Info(\"Paid services being used\")\n",
    "        return CodeBuddy(\"openai\", model)\n",
    "    elif model == \"llama3.2\":\n",
    "        return CodeBuddy(\"ollama\", model)\n",
    "    else:\n",
    "        raise ValueError(f\"{model} model not supported\")\n",
    "\n",
    "def initialize_sst(model): #stt: speech to text\n",
    "    if model == \"whisper-1\":\n",
    "        gr.Info(\"Paid services being used\")\n",
    "        return Transcriber(\"openai\", model)\n",
    "    elif model in [\"base\", \"small\", \"medium\", \"large\"]: #Supportd models for whisper\n",
    "        return Transcriber(\"whisper\", model)\n",
    "    else:\n",
    "        raise ValueError(f\"{model} model not supported\")\n",
    "\n",
    "def chat_stream(message, history, cbModel, buddy): \n",
    "    history = history or []\n",
    "\n",
    "    # If buddy is None or model changed, reinitialize\n",
    "    if buddy is None or buddy.modelName != cbModel:\n",
    "        buddy = initialize_buddy(cbModel)\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    messages = [{\"role\": \"system\", \"content\": systemPrompt}] + history\n",
    "\n",
    "    stream = buddy.runChatbot(userPrompt=history, systemPrompt=systemPrompt)\n",
    "\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        reply += chunk.choices[0].delta.content or \"\"\n",
    "        yield \"\", history + [{\"role\": \"assistant\", \"content\": reply}], buddy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c9438-63bb-42f3-9a19-3f012c5a9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row(scale=4):\n",
    "        with gr.Column(scale=1):\n",
    "            # Dropdown for the CodeBuddy model\n",
    "            modelName = gr.Dropdown(\n",
    "                choices=[\"llama3.2\", \"gpt-4o-mini\"],\n",
    "                label=\"Select Model\",\n",
    "                value=\"gpt-4o-mini\"\n",
    "            )\n",
    "            # Dropdown for thr trancribing model\n",
    "            trancriberModelName = gr.Dropdown(\n",
    "                choices=[\"whisper-1\", \"base\", \"small\", \"medium\", \"large\"],\n",
    "                label=\"Select Transcribing Model:\",\n",
    "                value=\"medium\"\n",
    "            )\n",
    "            # Input audio for the trancribing model\n",
    "            mic_input = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Speak now\") \n",
    "            # Entry (Text) to the CodeBuddy\n",
    "            entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "        with gr.Column(scale=2):\n",
    "            # Chatbot window\n",
    "            chatbot = gr.Chatbot(height=800, type=\"messages\")\n",
    "\n",
    "    with gr.Row(scale=1):\n",
    "        # Button to clear everything\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Status check of the models\n",
    "    buddyState = gr.State(value=None)\n",
    "    transcriberState = gr.State(value=None)  # ðŸ”§ store transcriber instance\n",
    "\n",
    "    # Transcribe audio to entry textbox\n",
    "    def handle_audio(audio_path, model, transcriber):\n",
    "        if audio_path is None:\n",
    "            return \"\", transcriber\n",
    "        \n",
    "        # Init transcriber if needed\n",
    "        if transcriber is None or transcriber.modelName != model:\n",
    "            transcriber = initialize_sst(model)\n",
    "\n",
    "        transcript = transcriber.run(audio_path)\n",
    "        return transcript, transcriber\n",
    "\n",
    "    # Mic input feed to the entry \n",
    "    mic_input.change(\n",
    "        fn=handle_audio,\n",
    "        inputs=[mic_input, trancriberModelName, transcriberState],\n",
    "        outputs=[entry, transcriberState]\n",
    "    )\n",
    "\n",
    "    # Main chatbot function\n",
    "    entry.submit(\n",
    "        fn=chat_stream,\n",
    "        inputs=[entry, chatbot, modelName, buddyState],\n",
    "        outputs=[entry, chatbot, buddyState]\n",
    "    )\n",
    "\n",
    "    # Clear button now resets everything\n",
    "    clear.click(\n",
    "        fn=lambda: (\"\", None, []), # Sets entry to \"\", mic_input to None and chatbot to []\n",
    "        inputs=[],\n",
    "        outputs=[entry, mic_input, chatbot],\n",
    "        queue=False\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ababb0-a6a7-4fc6-a663-0e2be10f56c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
