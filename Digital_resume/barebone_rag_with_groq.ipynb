{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572e07-8da2-4cb0-8f84-640638d53d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b9b48-5891-4942-9d84-37e3648ea8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from IPython.display import Markdown, display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db26cf-2a55-4a98-b7cb-55e1e0a6fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY', 'your-key-if-not-using-env')\n",
    "groq = Groq(api_key=os.environ[\"GROQ_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299dce-ba08-4fbe-b05d-1d5ff2501861",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"guru_db\"\n",
    "LLM_MODEL_NAME = \"llama-3.1-8b-instant\"#\"openai/gpt-oss-20b\",#\"groq/compound\"\n",
    "TTS_MODEL_NAME = \"playai-tts\"\n",
    "TTS_VOICE = \"Atlas-PlayAI\"\n",
    "TTS_RESPONSE_FORMAT = \"wav\"\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea627a0-d432-4cec-96bd-06a452db2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033c6f9-c5f2-452b-bdad-45605b72f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca80920-272c-4639-9077-dc40b7961e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "docs = retriever.get_relevant_documents(\"What are your Certifications?\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25b1b1-304d-417d-9e7f-8431fc14f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the docs to string\n",
    "def retDocToStr(docs):\n",
    "    doc_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_str += f\"{doc.metadata['doc_type']}\" + f\"\\n{doc.page_content}\\n\\n\"\n",
    "    return doc_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cb959-7d72-4ed3-8c9a-874fe53f2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Guru Deep Singh\"\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "You are allowed to provide all information given to you as Context including URLs, email,etc. \\\n",
    "ALWAYS answer as {name}. Never say your are a Large Language Model. Use ONLY the following context to answer. If the answer isn't in the context, say \\\"I don't know.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863516a-0074-4c50-ad64-8e62ccefb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to to get LLM response\n",
    "def ask_llm(prompt, vecStore, k=10):\n",
    "    retriever = vecStore.as_retriever(search_kwargs={\"k\": k})\n",
    "    docs = retriever.get_relevant_documents(prompt)\n",
    "    context = retDocToStr(docs)\n",
    "    msgs = [{\"role\":\"system\",\"content\":system_prompt},\n",
    "            {\"role\":\"user\",\"content\":f\"### CONTEXT: {context}\\n\\nUSER QUESTION: {prompt}\"}]\n",
    "    print(\"RAG CONTEXT: \", msgs)\n",
    "    resp = groq.chat.completions.create(\n",
    "        model=LLM_MODEL_NAME,\n",
    "        messages=msgs,\n",
    "        temperature=0.5,\n",
    "        stream=False,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a3aa5-be94-4310-ac7b-a2ee300aa37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "prompt = \"Tell me about yourself.\"\n",
    "out = ask_llm(prompt, vectorstore, 20)\n",
    " display(Markdown(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6525a5-0e09-4498-97e3-6d89cc5b5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run TTS\n",
    "def textToSpeech(text):\n",
    "    response = groq.audio.speech.create(\n",
    "        model=TTS_MODEL_NAME,\n",
    "        voice=TTS_VOICE,\n",
    "        input=text,\n",
    "        response_format=TTS_RESPONSE_FORMAT\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e42d2e-df29-4aad-a855-868ed25ef2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run LLM + TTS\n",
    "def ask_llm_speech(prompt, vecStore, k=10, speech=True):\n",
    "    response = ask_llm(prompt, vecStore, k)\n",
    "    if speech:\n",
    "        return response, textToSpeech(response)\n",
    "    else:\n",
    "        return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d673ae-44dc-4939-9685-6cd4d12276b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are your GRE and IELTS score?\"\n",
    "res = ask_llm_speech(prompt, vectorstore, 20, True)\n",
    "\n",
    "if isinstance(res, tuple):            # two outputs: (text, audio)\n",
    "    answer, voice = res\n",
    "else:                                  # one output: text only\n",
    "    answer, voice = res, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d378f4d-5867-41a0-a539-d41b0db1d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "display(Markdown(answer))\n",
    "\n",
    "if voice:\n",
    "    # Voice\n",
    "    speech_file_path = \"speech.wav\"\n",
    "    voice.write_to_file(speech_file_path)  # helper on BinaryAPIResponse\n",
    "    display(Audio(speech_file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
